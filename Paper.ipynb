{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paper",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "koOAdRsK5Obq"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import csv\n",
        "import urllib\n",
        "import cv2\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import PIL\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from matplotlib import pyplot as plt\n",
        "from copy import deepcopy\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "from socket import timeout\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUdcHB5Q5PSG",
        "outputId": "82f3871f-80a7-4b91-91ad-4614da70e7a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGXinqqZ5WCq"
      },
      "source": [
        "images = np.load('/content/drive/My Drive/Colab Notebooks/Paper/imgs.npy')\n",
        "masks = np.load('/content/drive/My Drive/Colab Notebooks/Paper/masks.npy')\n",
        "images = np.clip(images,1030,1090)-1030\n",
        "\n",
        "xy = np.where(masks>0)[1:]\n",
        "x1,x2,y1,y2 = xy[0].min(),xy[0].max(),xy[1].min(),xy[1].max()\n",
        "dx,dy = x2-x1+1,y2-y1+1\n",
        "\n",
        "imgr = np.stack([x[x1:x2+1,y1:y2+1] for x in images])\n",
        "maskr = np.stack([x[x1:x2+1,y1:y2+1].astype('uint8') for x in masks])\n",
        "\n",
        "imgr = np.stack([cv2.resize(x, (256,256)) for x in images])\n",
        "maskr = np.stack([cv2.resize(x.astype('uint8'), (256,256)) for x in masks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql5cyeIm5bU3",
        "outputId": "32252834-b011-430c-bd58-ebcf5fc171c1"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.Tensor(list(data)).float()\n",
        "        self.target = torch.Tensor(list(target)).float()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index].resize_((1,256,256))\n",
        "        y = self.target[index].resize_((1,256,256))\n",
        "        \n",
        "        if self.transform:\n",
        "            data = torch.cat()\n",
        "            x = self.transform(x)\n",
        "            x, y = data[0], data[1] \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "numpy_data = imgr\n",
        "numpy_target = maskr\n",
        "batch_size = 5 \n",
        "\n",
        "dataset = MyDataset(numpy_data, numpy_target)\n",
        "ind = np.random.permutation(25)\n",
        " \n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.Subset(dataset, ind[0:20]),torch.utils.data.Subset(dataset, ind[20:25])\n",
        "\n",
        "train_batch = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)\n",
        "\n",
        "test_batch = torch.utils.data.DataLoader(test_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(train_batch):\n",
        "    print('Batch idx {}, data shape {}, target shape {}'.format(\n",
        "        batch_idx, data.shape, target.shape))\n",
        "    \n",
        "\n",
        "for batch_idx, (data, target) in enumerate(test_batch):\n",
        "    print('Batch idx {}, data shape {}, target shape {}'.format(\n",
        "        batch_idx, data.shape, target.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch idx 0, data shape torch.Size([5, 1, 256, 256]), target shape torch.Size([5, 1, 256, 256])\n",
            "Batch idx 1, data shape torch.Size([5, 1, 256, 256]), target shape torch.Size([5, 1, 256, 256])\n",
            "Batch idx 2, data shape torch.Size([5, 1, 256, 256]), target shape torch.Size([5, 1, 256, 256])\n",
            "Batch idx 3, data shape torch.Size([5, 1, 256, 256]), target shape torch.Size([5, 1, 256, 256])\n",
            "Batch idx 0, data shape torch.Size([5, 1, 256, 256]), target shape torch.Size([5, 1, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3LOQ3TK5dN1"
      },
      "source": [
        "class SoftDice():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "  \n",
        "    def __call__(self, prediction, ground_truth):\n",
        "        n_images = len(prediction)\n",
        "        loss = 2*torch.mul(prediction, ground_truth).sum()\n",
        "        loss/=((prediction.sum()) + (ground_truth.sum()))\n",
        "        return torch.clamp(loss,min=1e-7,max=1-1e-7)\n",
        "        \n",
        "def compute_loss(X, y):\n",
        "    X = Variable(X).cuda()\n",
        "    y = Variable(y).cuda()\n",
        "    logits = model.cuda()(X)\n",
        "    loss = torch.nn.BCELoss()\n",
        "    # loss = BCE()\n",
        "    lossDice = SoftDice()\n",
        "    # # return loss(logits, y)\n",
        "    return loss(logits, y) + (1-lossDice(logits, y))\n",
        "    # # return loss(logits, y) - torch.log(lossDice(logits, y))\n",
        "    # return 1 - lossDice(logits, y)\n",
        "\n",
        "class BoundaryLoss(nn.Module):\n",
        "    def __init__(self, theta0=3, theta=5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.theta0 = theta0\n",
        "        self.theta = theta\n",
        "\n",
        "    def forward(self, pred, gt):\n",
        "\n",
        "        n, c, _, _ = pred.shape\n",
        "\n",
        "        # softmax so that predicted map can be distributed in [0, 1]\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "\n",
        "        # one-hot vector of ground truth\n",
        "        one_hot_gt = one_hot(gt, c)\n",
        "\n",
        "        # boundary map\n",
        "        gt_b = F.max_pool2d(\n",
        "            1 - one_hot_gt, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
        "        gt_b -= 1 - one_hot_gt\n",
        "\n",
        "        pred_b = F.max_pool2d(\n",
        "            1 - pred, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
        "        pred_b -= 1 - pred\n",
        "\n",
        "        # extended boundary map\n",
        "        gt_b_ext = F.max_pool2d(\n",
        "            gt_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
        "\n",
        "        pred_b_ext = F.max_pool2d(\n",
        "            pred_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
        "\n",
        "        # reshape\n",
        "        gt_b = gt_b.view(n, c, -1)\n",
        "        pred_b = pred_b.view(n, c, -1)\n",
        "        gt_b_ext = gt_b_ext.view(n, c, -1)\n",
        "        pred_b_ext = pred_b_ext.view(n, c, -1)\n",
        "\n",
        "        # Precision, Recall\n",
        "        P = torch.sum(pred_b * gt_b_ext, dim=2) / (torch.sum(pred_b, dim=2) + 1e-7)\n",
        "        R = torch.sum(pred_b_ext * gt_b, dim=2) / (torch.sum(gt_b, dim=2) + 1e-7)\n",
        "\n",
        "        # Boundary F1 Score\n",
        "        BF1 = 2 * P * R / (P + R + 1e-7)\n",
        "\n",
        "        # summing BF1 Score for each class and average over mini-batch\n",
        "        loss = torch.mean(1 - BF1)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdfYTCKb6niZ"
      },
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func=func\n",
        "\n",
        "    def forward(self, x): \n",
        "        return torch.FloatTensor(self.func(x.cpu()))\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, kernel_size=3, activation=F.relu, padding = 1):\n",
        "        super(DownBlock, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(in_size, out_size, kernel_size, padding=1)\n",
        "        self.conv1 = nn.Conv2d(out_size, out_size, kernel_size, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_size, out_size, kernel_size, padding=1)\n",
        "        self.drop = nn.Dropout2d(0.05)\n",
        "        self.BN1 = nn.BatchNorm2d(out_size)\n",
        "        self.BN2 = nn.BatchNorm2d(out_size)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.activation(self.conv0(x))\n",
        "        out = self.drop(out)\n",
        "        # out = self.drop(out)\n",
        "        # out = self.BN1(out)\n",
        "        # out = self.activation(self.conv1(out))\n",
        "        out = self.BN1(out)\n",
        "        out = self.activation(self.conv2(out))\n",
        "        out = self.BN2(out)\n",
        "        out = self.drop(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MiddleBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, kernel_size=3, activation=F.relu, padding = 1):\n",
        "        super(MiddleBlock, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(in_size, out_size, kernel_size, padding=1)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.activation(self.conv0(x))\n",
        "        return out\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, kernel_size=3, activation=F.relu, space_dropout=False,padding=1):\n",
        "        super(UpBlock, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_size, out_size, 2, stride=2)\n",
        "        self.conv = nn.Conv2d(in_size, out_size, kernel_size,padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_size, out_size, kernel_size,padding=1)\n",
        "        self.activation = activation\n",
        "\n",
        "    def center_crop(self, layer, target_size):\n",
        "        batch_size, n_channels, layer_width, layer_height = layer.size()\n",
        "        xy1 = (layer_width - target_size) // 2\n",
        "        return layer[:, :, xy1:(xy1 + target_size), xy1:(xy1 + target_size)]\n",
        "\n",
        "    def forward(self, x, bridge):\n",
        "        up = self.up(x)\n",
        "        crop1 = self.center_crop(bridge, up.size()[2])\n",
        "        out = torch.cat([up, crop1], 1)\n",
        "        out = self.activation(self.conv(out))\n",
        "        out = self.activation(self.conv2(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_size, out_size, kernel_size=3, activation=F.relu, space_dropout=False,padding=1):\n",
        "        super(Up, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_size, out_size, kernel_size,padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_size, out_size, kernel_size,padding=1)\n",
        "        self.activation = activation\n",
        "        self.BN = nn.BatchNorm2d(out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.BN(self.activation(self.conv(x)))\n",
        "        out = self.BN(self.activation(self.conv2(out)))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vee8Q6S5g6K"
      },
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=4):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // 2, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // 2, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=3):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size = 3, padding=1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class AttentionBlockEncoder(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super(AttentionBlockEncoder, self).__init__()\n",
        "        \n",
        "        self.ca = ChannelAttention(in_planes)\n",
        "        self.sa = SpatialAttention(kernel_size = 3)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        # print('a:', self.ca(x).size(), self.sa(x).size(), x.size())\n",
        "        ca = self.ca(x) * x\n",
        "        sa = self.sa(ca) * ca\n",
        "\n",
        "        # print('size:', (ca+sa).size())\n",
        "\n",
        "        # return ca + sa + x\n",
        "        return sa + x\n",
        "\n",
        "class AttentionBlockDecoder(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super(AttentionBlockDecoder, self).__init__()\n",
        "        \n",
        "        self.ca = ChannelAttention(in_planes)\n",
        "        self.sa = SpatialAttention(kernel_size = 3)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        # print('a:', self.ca(x).size(), self.sa(x).size(), x.size())\n",
        "        ca = self.ca(x) * x\n",
        "        sa = self.sa(x) * x\n",
        "\n",
        "        # print('size:', (ca+sa).size())\n",
        "\n",
        "        # return ca + sa + x\n",
        "        return sa+sa\n",
        "\n",
        "\n",
        "class CA(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super(CA, self).__init__()\n",
        "        \n",
        "        self.ca = ChannelAttention(in_planes)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        # print('a:', self.ca(x).size(), self.sa(x).size(), x.size())\n",
        "        ca = self.ca(x) * x\n",
        "\n",
        "        return ca + x\n",
        "\n",
        "class SA(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super(SA, self).__init__()\n",
        "        \n",
        "        self.sa = SpatialAttention(in_planes)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        # print('a:', self.ca(x).size(), self.sa(x).size(), x.size())\n",
        "        sa = self.sa(x) * x\n",
        "\n",
        "        return sa + x\n",
        "\n",
        "class Att_CAxSA(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super(Att_CAxSA, self).__init__()\n",
        "        self.ca = ChannelAttention(in_planes)\n",
        "        self.sa = SpatialAttention(kernel_size = 3)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        # print('a:', self.ca(x).size(), self.sa(x).size(), x.size())\n",
        "        ca = self.ca(x) * x\n",
        "        sa = self.sa(ca) * ca\n",
        "\n",
        "        # print('size:', (ca+sa).size())\n",
        "\n",
        "        # return ca + sa + x\n",
        "        return sa + x\n",
        "\n",
        "class Att_CA_SA(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super(Att_CA_SA, self).__init__()\n",
        "        self.ca = ChannelAttention(in_planes)\n",
        "        self.sa = SpatialAttention(kernel_size = 3)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        # print('a:', self.ca(x).size(), self.sa(x).size(), x.size())\n",
        "        ca = self.ca(x) * x\n",
        "        sa = self.sa(x) * x\n",
        "\n",
        "        return sa+sa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bERVdViy5_Vf"
      },
      "source": [
        "class UNet_CAxSA(nn.Module):\n",
        "    def __init__(self, imsize):\n",
        "        super(UNet_CAxSA, self).__init__()\n",
        "        self.imsize = imsize\n",
        "\n",
        "        self.activation = F.relu\n",
        "        \n",
        "        k = 1\n",
        "        \n",
        "        self.Lambda = Lambda(lambda x: x/255)\n",
        "        # self.Lambda = Lambda(lambda x: x/60)\n",
        "       \n",
        "        self.conv0= DownBlock(1*k, 8*k)\n",
        "        self.encoder_att0 = AttentionBlockEncoder(8*k)\n",
        "        self.pool0 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv1= DownBlock(1*k, 16*k)\n",
        "        self.encoder_att1 = AttentionBlockEncoder(16*k)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = DownBlock(16*k, 32*k)\n",
        "        self.encoder_att2 = AttentionBlockEncoder(32*k)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3 = DownBlock(32*k, 64*k)\n",
        "        self.encoder_att3 = AttentionBlockEncoder(64*k)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        #add blocks\n",
        "        self.bottle_neck = MiddleBlock(64*k,128*k)        \n",
        "\n",
        "        self.up_att1 = nn.ConvTranspose2d(128*k, 64*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.up1 = nn.ConvTranspose2d(128*k, 64*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.att1 = Att_CAxSA(64*k)\n",
        "        self.forw1 = Up(128*k, 64*k)\n",
        "\n",
        "        self.up_att2 = nn.ConvTranspose2d(64*k,32*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.up2 = nn.ConvTranspose2d(64*k,32*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.att2 = Att_CAxSA(32*k)\n",
        "        self.forw2 = Up(64*k, 32*k)\n",
        "\n",
        "        self.up_att3 = nn.ConvTranspose2d(32*k, 16*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.up3 = nn.ConvTranspose2d(32*k, 16*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.att3 = Att_CAxSA(16*k)\n",
        "        self.forw3 = Up(32*k, 16*k)\n",
        "\n",
        "        self.last = nn.Conv2d(16*k, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Lambda(x).cuda()\n",
        "\n",
        "        block1 = self.conv1(x)\n",
        "        encoder_att1 = self.encoder_att1(block1)\n",
        "        pool1 = self.pool1(block1)\n",
        " \n",
        "        block2 = self.conv2(pool1)\n",
        "        encoder_att2 = self.encoder_att2(block2)\n",
        "        pool2 = self.pool2(block2)\n",
        "\n",
        "        block3 = self.conv3(pool2)\n",
        "        encoder_att3 = self.encoder_att3(block3)\n",
        "        pool3 = self.pool3(block3)\n",
        "\n",
        "        block4 = self.bottle_neck(pool3)\n",
        "\n",
        "        up_att1 = self.up_att1(block4)\n",
        "        up1 = self.up1(block4)\n",
        "        att1 = self.att1(up_att1 + encoder_att3)\n",
        "        forw1 = self.forw1(torch.cat([att1, up1], 1))\n",
        "        \n",
        "        up_att2 = self.up_att2(forw1)\n",
        "        up2 = self.up2(forw1)\n",
        "        att2 = self.att2(up_att2 + encoder_att2)\n",
        "        forw2 = self.forw2(torch.cat([att2, up2], 1))\n",
        "\n",
        "        up_att3 = self.up_att3(forw2)\n",
        "        up3 = self.up3(forw2)\n",
        "        att3 = self.att3(up_att3 + encoder_att1)\n",
        "        forw3 = self.forw3(torch.cat([att3, up3], 1))\n",
        "        \n",
        "        out = self.last(forw3)\n",
        "\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class UNet_CA_SA(nn.Module):\n",
        "    def __init__(self, imsize):\n",
        "        super(UNet_CA_SA, self).__init__()\n",
        "        self.imsize = imsize\n",
        "\n",
        "        self.activation = F.relu\n",
        "  \n",
        "        k = 1\n",
        "        \n",
        "        self.Lambda = Lambda(lambda x: x/255)\n",
        "        # self.Lambda = Lambda(lambda x: x/60)\n",
        "       \n",
        "        self.conv0= DownBlock(1*k, 8*k)\n",
        "        self.encoder_att0 = AttentionBlockEncoder(8*k)\n",
        "        self.pool0 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv1= DownBlock(1*k, 16*k)\n",
        "        self.encoder_att1 = AttentionBlockEncoder(16*k)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = DownBlock(16*k, 32*k)\n",
        "        self.encoder_att2 = AttentionBlockEncoder(32*k)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3 = DownBlock(32*k, 64*k)\n",
        "        self.encoder_att3 = AttentionBlockEncoder(64*k)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        #add blocks\n",
        "        self.bottle_neck = MiddleBlock(64*k,128*k)        \n",
        "\n",
        "        self.up_att1 = nn.ConvTranspose2d(128*k, 64*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.up1 = nn.ConvTranspose2d(128*k, 64*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.att1 = Att_CA_SA(64*k)\n",
        "        self.forw1 = Up(128*k, 64*k)\n",
        "\n",
        "        self.up_att2 = nn.ConvTranspose2d(64*k,32*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.up2 = nn.ConvTranspose2d(64*k,32*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.att2 = Att_CA_SA(32*k)\n",
        "        self.forw2 = Up(64*k, 32*k)\n",
        "\n",
        "        self.up_att3 = nn.ConvTranspose2d(32*k, 16*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.up3 = nn.ConvTranspose2d(32*k, 16*k, 3, stride=2, padding=1, output_padding = 1)\n",
        "        self.att3 = Att_CA_SA(16*k)\n",
        "        self.forw3 = Up(32*k, 16*k)\n",
        "\n",
        "        self.last = nn.Conv2d(16*k, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Lambda(x).cuda()\n",
        "\n",
        "        block1 = self.conv1(x)\n",
        "        encoder_att1 = self.encoder_att1(block1)\n",
        "        pool1 = self.pool1(block1)\n",
        " \n",
        "        block2 = self.conv2(pool1)\n",
        "        encoder_att2 = self.encoder_att2(block2)\n",
        "        pool2 = self.pool2(block2)\n",
        "\n",
        "        block3 = self.conv3(pool2)\n",
        "        encoder_att3 = self.encoder_att3(block3)\n",
        "        pool3 = self.pool3(block3)\n",
        "\n",
        "        block4 = self.bottle_neck(pool3)\n",
        "\n",
        "        up_att1 = self.up_att1(block4)\n",
        "        up1 = self.up1(block4)\n",
        "        att1 = self.att1(up_att1 + encoder_att3)\n",
        "        forw1 = self.forw1(torch.cat([att1, up1], 1))\n",
        "        \n",
        "        up_att2 = self.up_att2(forw1)\n",
        "        up2 = self.up2(forw1)\n",
        "        att2 = self.att2(up_att2 + encoder_att2)\n",
        "        forw2 = self.forw2(torch.cat([att2, up2], 1))\n",
        "\n",
        "        up_att3 = self.up_att3(forw2)\n",
        "        up3 = self.up3(forw2)\n",
        "        att3 = self.att3(up_att3 + encoder_att1)\n",
        "        forw3 = self.forw3(torch.cat([att3, up3], 1))\n",
        "        \n",
        "        out = self.last(forw3)\n",
        "\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class UNet_SA(nn.Module):\n",
        "    def __init__(self, imsize):\n",
        "        super(UNet_BN, self).__init__()\n",
        "        self.imsize = imsize\n",
        "\n",
        "        self.activation = F.relu\n",
        "        \n",
        "        k = 1\n",
        "        \n",
        "        self.Lambda = Lambda(lambda x: x/255)\n",
        "        # self.Lambda = Lambda(lambda x: x/60)\n",
        "       \n",
        "        self.conv0= DownBlock(1*k, 8*k)\n",
        "        self.encoder_att0 = AttentionBlockEncoder(8*k)\n",
        "        self.pool0 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv1= DownBlock(1*k, 16*k)\n",
        "        self.encoder_att1 = AttentionBlockEncoder(16*k)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = DownBlock(16*k, 32*k)\n",
        "        self.encoder_att2 = AttentionBlockEncoder(32*k)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3 = DownBlock(32*k, 64*k)\n",
        "        self.encoder_att3 = AttentionBlockEncoder(64*k)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        #add blocks\n",
        "        self.bottle_neck = MiddleBlock(64*k,128*k)        \n",
        "\n",
        "        self.up_block1 = UpBlock(128*k, 64*k)\n",
        "        self.Att1 = SA(128*k, 64*k)\n",
        "        self.up_block2 = UpBlock(64*k, 32*k)\n",
        "        self.Att2 = SA(64*k, 32*k)\n",
        "        self.up_block3 = UpBlock(32*k, 16*k)\n",
        "        self.Att3 = SA(32*k, 16*k)\n",
        "\n",
        "        self.last = nn.Conv2d(16*k, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Lambda(x).cuda()\n",
        "\n",
        "        block1 = self.conv1(x)\n",
        "        encoder_att1 = self.encoder_att1(block1)\n",
        "        pool1 = self.pool1(block1)\n",
        " \n",
        "        block2 = self.conv2(pool1)\n",
        "        encoder_att2 = self.encoder_att2(block2)\n",
        "        pool2 = self.pool2(block2)\n",
        "\n",
        "        block3 = self.conv3(pool2)\n",
        "        encoder_att3 = self.encoder_att3(block3)\n",
        "        pool3 = self.pool3(block3)\n",
        "\n",
        "        block4 = self.bottle_neck(pool3)\n",
        "\n",
        "       \n",
        "        up1 = self.up_block1(block4, block3)\n",
        "        \n",
        "        up2 = self.up_block2(up1, block2)\n",
        "  \n",
        "        up3 = self.up_block3(up2, block1)\n",
        "        \n",
        "        out = self.last(up3)\n",
        "\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class UNet_CA(nn.Module):\n",
        "    def __init__(self, imsize):\n",
        "        super(UNet_BN, self).__init__()\n",
        "        self.imsize = imsize\n",
        "\n",
        "        self.activation = F.relu\n",
        "        \n",
        "        k = 1\n",
        "        \n",
        "        self.Lambda = Lambda(lambda x: x/255)\n",
        "        # self.Lambda = Lambda(lambda x: x/60)\n",
        "       \n",
        "        self.conv0= DownBlock(1*k, 8*k)\n",
        "        self.encoder_att0 = AttentionBlockEncoder(8*k)\n",
        "        self.pool0 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv1= DownBlock(1*k, 16*k)\n",
        "        self.encoder_att1 = AttentionBlockEncoder(16*k)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv2 = DownBlock(16*k, 32*k)\n",
        "        self.encoder_att2 = AttentionBlockEncoder(32*k)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.conv3 = DownBlock(32*k, 64*k)\n",
        "        self.encoder_att3 = AttentionBlockEncoder(64*k)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        #add blocks\n",
        "        self.bottle_neck = MiddleBlock(64*k,128*k)        \n",
        "\n",
        "        self.up_block1 = UpBlock(128*k, 64*k)\n",
        "        self.Att1 = SA(128*k, 64*k)\n",
        "        self.up_block2 = UpBlock(64*k, 32*k)\n",
        "        self.Att2 = SA(64*k, 32*k)\n",
        "        self.up_block3 = UpBlock(32*k, 16*k)\n",
        "        self.Att3 = SA(32*k, 16*k)\n",
        "\n",
        "        self.last = nn.Conv2d(16*k, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Lambda(x).cuda()\n",
        "\n",
        "        block1 = self.conv1(x)\n",
        "        encoder_att1 = self.encoder_att1(block1)\n",
        "        pool1 = self.pool1(block1)\n",
        " \n",
        "        block2 = self.conv2(pool1)\n",
        "        encoder_att2 = self.encoder_att2(block2)\n",
        "        pool2 = self.pool2(block2)\n",
        "\n",
        "        block3 = self.conv3(pool2)\n",
        "        encoder_att3 = self.encoder_att3(block3)\n",
        "        pool3 = self.pool3(block3)\n",
        "\n",
        "        block4 = self.bottle_neck(pool3)\n",
        "\n",
        "       \n",
        "        up1 = self.up_block1(block4, block3)\n",
        "        \n",
        "        up2 = self.up_block2(up1, block2)\n",
        "  \n",
        "        up3 = self.up_block3(up2, block1)\n",
        "        \n",
        "        out = self.last(up3)\n",
        "\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELfWyWOK8Bdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92995042-d6f6-4c67-e037-4161e3899fef"
      },
      "source": [
        "model = UNet_CA_SA(256)\n",
        "summary(model.cuda(), (1, 256, 256))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Lambda-1          [-1, 1, 256, 256]               0\n",
            "            Conv2d-2         [-1, 16, 256, 256]             160\n",
            "         Dropout2d-3         [-1, 16, 256, 256]               0\n",
            "       BatchNorm2d-4         [-1, 16, 256, 256]              32\n",
            "            Conv2d-5         [-1, 16, 256, 256]           2,320\n",
            "       BatchNorm2d-6         [-1, 16, 256, 256]              32\n",
            "         Dropout2d-7         [-1, 16, 256, 256]               0\n",
            "         DownBlock-8         [-1, 16, 256, 256]               0\n",
            " AdaptiveAvgPool2d-9             [-1, 16, 1, 1]               0\n",
            "           Conv2d-10              [-1, 8, 1, 1]             128\n",
            "             ReLU-11              [-1, 8, 1, 1]               0\n",
            "           Conv2d-12             [-1, 16, 1, 1]             128\n",
            "AdaptiveMaxPool2d-13             [-1, 16, 1, 1]               0\n",
            "           Conv2d-14              [-1, 8, 1, 1]             128\n",
            "             ReLU-15              [-1, 8, 1, 1]               0\n",
            "           Conv2d-16             [-1, 16, 1, 1]             128\n",
            "          Sigmoid-17             [-1, 16, 1, 1]               0\n",
            " ChannelAttention-18             [-1, 16, 1, 1]               0\n",
            "           Conv2d-19          [-1, 1, 256, 256]              18\n",
            "          Sigmoid-20          [-1, 1, 256, 256]               0\n",
            " SpatialAttention-21          [-1, 1, 256, 256]               0\n",
            "AttentionBlockEncoder-22         [-1, 16, 256, 256]               0\n",
            "        MaxPool2d-23         [-1, 16, 128, 128]               0\n",
            "           Conv2d-24         [-1, 32, 128, 128]           4,640\n",
            "        Dropout2d-25         [-1, 32, 128, 128]               0\n",
            "      BatchNorm2d-26         [-1, 32, 128, 128]              64\n",
            "           Conv2d-27         [-1, 32, 128, 128]           9,248\n",
            "      BatchNorm2d-28         [-1, 32, 128, 128]              64\n",
            "        Dropout2d-29         [-1, 32, 128, 128]               0\n",
            "        DownBlock-30         [-1, 32, 128, 128]               0\n",
            "AdaptiveAvgPool2d-31             [-1, 32, 1, 1]               0\n",
            "           Conv2d-32             [-1, 16, 1, 1]             512\n",
            "             ReLU-33             [-1, 16, 1, 1]               0\n",
            "           Conv2d-34             [-1, 32, 1, 1]             512\n",
            "AdaptiveMaxPool2d-35             [-1, 32, 1, 1]               0\n",
            "           Conv2d-36             [-1, 16, 1, 1]             512\n",
            "             ReLU-37             [-1, 16, 1, 1]               0\n",
            "           Conv2d-38             [-1, 32, 1, 1]             512\n",
            "          Sigmoid-39             [-1, 32, 1, 1]               0\n",
            " ChannelAttention-40             [-1, 32, 1, 1]               0\n",
            "           Conv2d-41          [-1, 1, 128, 128]              18\n",
            "          Sigmoid-42          [-1, 1, 128, 128]               0\n",
            " SpatialAttention-43          [-1, 1, 128, 128]               0\n",
            "AttentionBlockEncoder-44         [-1, 32, 128, 128]               0\n",
            "        MaxPool2d-45           [-1, 32, 64, 64]               0\n",
            "           Conv2d-46           [-1, 64, 64, 64]          18,496\n",
            "        Dropout2d-47           [-1, 64, 64, 64]               0\n",
            "      BatchNorm2d-48           [-1, 64, 64, 64]             128\n",
            "           Conv2d-49           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-50           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-51           [-1, 64, 64, 64]               0\n",
            "        DownBlock-52           [-1, 64, 64, 64]               0\n",
            "AdaptiveAvgPool2d-53             [-1, 64, 1, 1]               0\n",
            "           Conv2d-54             [-1, 32, 1, 1]           2,048\n",
            "             ReLU-55             [-1, 32, 1, 1]               0\n",
            "           Conv2d-56             [-1, 64, 1, 1]           2,048\n",
            "AdaptiveMaxPool2d-57             [-1, 64, 1, 1]               0\n",
            "           Conv2d-58             [-1, 32, 1, 1]           2,048\n",
            "             ReLU-59             [-1, 32, 1, 1]               0\n",
            "           Conv2d-60             [-1, 64, 1, 1]           2,048\n",
            "          Sigmoid-61             [-1, 64, 1, 1]               0\n",
            " ChannelAttention-62             [-1, 64, 1, 1]               0\n",
            "           Conv2d-63            [-1, 1, 64, 64]              18\n",
            "          Sigmoid-64            [-1, 1, 64, 64]               0\n",
            " SpatialAttention-65            [-1, 1, 64, 64]               0\n",
            "AttentionBlockEncoder-66           [-1, 64, 64, 64]               0\n",
            "        MaxPool2d-67           [-1, 64, 32, 32]               0\n",
            "           Conv2d-68          [-1, 128, 32, 32]          73,856\n",
            "      MiddleBlock-69          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-70           [-1, 64, 64, 64]          73,792\n",
            "  ConvTranspose2d-71           [-1, 64, 64, 64]          73,792\n",
            "AdaptiveAvgPool2d-72             [-1, 64, 1, 1]               0\n",
            "           Conv2d-73             [-1, 32, 1, 1]           2,048\n",
            "             ReLU-74             [-1, 32, 1, 1]               0\n",
            "           Conv2d-75             [-1, 64, 1, 1]           2,048\n",
            "AdaptiveMaxPool2d-76             [-1, 64, 1, 1]               0\n",
            "           Conv2d-77             [-1, 32, 1, 1]           2,048\n",
            "             ReLU-78             [-1, 32, 1, 1]               0\n",
            "           Conv2d-79             [-1, 64, 1, 1]           2,048\n",
            "          Sigmoid-80             [-1, 64, 1, 1]               0\n",
            " ChannelAttention-81             [-1, 64, 1, 1]               0\n",
            "           Conv2d-82            [-1, 1, 64, 64]              18\n",
            "          Sigmoid-83            [-1, 1, 64, 64]               0\n",
            " SpatialAttention-84            [-1, 1, 64, 64]               0\n",
            "        Att_CA_SA-85           [-1, 64, 64, 64]               0\n",
            "           Conv2d-86           [-1, 64, 64, 64]          73,792\n",
            "      BatchNorm2d-87           [-1, 64, 64, 64]             128\n",
            "           Conv2d-88           [-1, 64, 64, 64]          36,928\n",
            "      BatchNorm2d-89           [-1, 64, 64, 64]             128\n",
            "               Up-90           [-1, 64, 64, 64]               0\n",
            "  ConvTranspose2d-91         [-1, 32, 128, 128]          18,464\n",
            "  ConvTranspose2d-92         [-1, 32, 128, 128]          18,464\n",
            "AdaptiveAvgPool2d-93             [-1, 32, 1, 1]               0\n",
            "           Conv2d-94             [-1, 16, 1, 1]             512\n",
            "             ReLU-95             [-1, 16, 1, 1]               0\n",
            "           Conv2d-96             [-1, 32, 1, 1]             512\n",
            "AdaptiveMaxPool2d-97             [-1, 32, 1, 1]               0\n",
            "           Conv2d-98             [-1, 16, 1, 1]             512\n",
            "             ReLU-99             [-1, 16, 1, 1]               0\n",
            "          Conv2d-100             [-1, 32, 1, 1]             512\n",
            "         Sigmoid-101             [-1, 32, 1, 1]               0\n",
            "ChannelAttention-102             [-1, 32, 1, 1]               0\n",
            "          Conv2d-103          [-1, 1, 128, 128]              18\n",
            "         Sigmoid-104          [-1, 1, 128, 128]               0\n",
            "SpatialAttention-105          [-1, 1, 128, 128]               0\n",
            "       Att_CA_SA-106         [-1, 32, 128, 128]               0\n",
            "          Conv2d-107         [-1, 32, 128, 128]          18,464\n",
            "     BatchNorm2d-108         [-1, 32, 128, 128]              64\n",
            "          Conv2d-109         [-1, 32, 128, 128]           9,248\n",
            "     BatchNorm2d-110         [-1, 32, 128, 128]              64\n",
            "              Up-111         [-1, 32, 128, 128]               0\n",
            " ConvTranspose2d-112         [-1, 16, 256, 256]           4,624\n",
            " ConvTranspose2d-113         [-1, 16, 256, 256]           4,624\n",
            "AdaptiveAvgPool2d-114             [-1, 16, 1, 1]               0\n",
            "          Conv2d-115              [-1, 8, 1, 1]             128\n",
            "            ReLU-116              [-1, 8, 1, 1]               0\n",
            "          Conv2d-117             [-1, 16, 1, 1]             128\n",
            "AdaptiveMaxPool2d-118             [-1, 16, 1, 1]               0\n",
            "          Conv2d-119              [-1, 8, 1, 1]             128\n",
            "            ReLU-120              [-1, 8, 1, 1]               0\n",
            "          Conv2d-121             [-1, 16, 1, 1]             128\n",
            "         Sigmoid-122             [-1, 16, 1, 1]               0\n",
            "ChannelAttention-123             [-1, 16, 1, 1]               0\n",
            "          Conv2d-124          [-1, 1, 256, 256]              18\n",
            "         Sigmoid-125          [-1, 1, 256, 256]               0\n",
            "SpatialAttention-126          [-1, 1, 256, 256]               0\n",
            "       Att_CA_SA-127         [-1, 16, 256, 256]               0\n",
            "          Conv2d-128         [-1, 16, 256, 256]           4,624\n",
            "     BatchNorm2d-129         [-1, 16, 256, 256]              32\n",
            "          Conv2d-130         [-1, 16, 256, 256]           2,320\n",
            "     BatchNorm2d-131         [-1, 16, 256, 256]              32\n",
            "              Up-132         [-1, 16, 256, 256]               0\n",
            "          Conv2d-133          [-1, 1, 256, 256]              17\n",
            "================================================================\n",
            "Total params: 507,309\n",
            "Trainable params: 507,309\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 234.45\n",
            "Params size (MB): 1.94\n",
            "Estimated Total Size (MB): 236.64\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQacnRt8Hhv"
      },
      "source": [
        "def Trainer(model, train_loader, val_loader,  optimizer, epochs, sheduler = None):\n",
        "    train_loss_history, train_accuracy, train_dice= [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 301:\n",
        "          break\n",
        "        else:\n",
        "          model.train(True)\n",
        "          for (X, y) in train_loader:\n",
        "            # loss, accuracy= compute_loss(X, y)\n",
        "            # dice = dice_coef(y,X)\n",
        "            loss = compute_loss(X, y)\n",
        "            loss.backward()\n",
        "            opt.step() \n",
        "            opt.zero_grad()\n",
        "            train_loss_history.append(loss.data.cpu().numpy())\n",
        "            # train_accuracy.append(accuracy)\n",
        "            # train_dice.append(dice)\n",
        "        \n",
        "        clear_output()\n",
        "        if sheduler is not None:\n",
        "            sheduler.step(train_loss_history[-1])\n",
        "        print(\"Last loss:\\t{}\\nEpoch number:\\t{}\\nCurrent Learning rate:{}\".format(train_loss_history[-1], epoch, optimizer.state_dict()['param_groups'][0]['lr']))\n",
        "        plt.plot(train_loss_history)\n",
        "        plt.show()\n",
        "        # if epoch == 15:\n",
        "        #   plt.savefig('train15_unetBN_svg.svg')\n",
        "        #   plt.savefig('train15_unetBN_png.png')\n",
        "        # elif epoch == 200:\n",
        "        #   plt.savefig('train200_unetBN_svg.svg')\n",
        "        #   plt.savefig('train200_unetBN_png.png')\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "shedule = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=20)\n",
        "num_epochs = 1000\n",
        "batch_size = 20\n",
        "try:\n",
        "  Trainer(model, train_batch, test_batch, epochs = num_epochs, optimizer=opt, sheduler=shedule)\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "dX7fvIlV8-Jn",
        "outputId": "be43be26-6e36-4bbc-d267-caff3ef3b736"
      },
      "source": [
        "for i in range(20):\n",
        "    %time\n",
        "    ind = np.random.permutation(range(0,25))\n",
        "\n",
        "    train_dataset, test_dataset = torch.utils.data.Subset(dataset, ind[0:20]),torch.utils.data.Subset(dataset, ind[20:25])\n",
        "\n",
        "    train_batch = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                  batch_size=batch_size,\n",
        "                                                  shuffle=True,\n",
        "                                                  num_workers=1)\n",
        "\n",
        "    test_batch = torch.utils.data.DataLoader(test_dataset, \n",
        "                                                  batch_size=batch_size,\n",
        "                                                  shuffle=True,\n",
        "                                                  num_workers=1)\n",
        "    \n",
        "    model = UNet_CA_SA(256)\n",
        "    summary(model.cuda(), (1, 256, 256))\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    shedule = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=20)\n",
        "    num_epochs = 1000\n",
        "    batch_size = 20\n",
        "    try:\n",
        "      Trainer(model, train_batch, test_batch, epochs = num_epochs, optimizer=opt, sheduler=shedule)\n",
        "    except KeyboardInterrupt:\n",
        "      pass\n",
        "    \n",
        "    img, mask = np.zeros(5), np.zeros(5)\n",
        "\n",
        "    for (x,y) in test_batch:\n",
        "        img = Variable(model(x.cuda())).cpu().numpy().reshape(5,256,256)\n",
        "        mask = Variable(y).numpy().reshape(5,256,256)\n",
        "        \n",
        "    im, mask = img.reshape(5, -1), mask.reshape(5, -1)\n",
        "    im.shape, mask.shape\n",
        "\n",
        "    dice_metric = []\n",
        "    for i,_ in enumerate(im):\n",
        "        inter = np.sum(im[i]*mask[i])\n",
        "        union = (np.sum(im[i])+np.sum(mask[i]))\n",
        "        dice_metric.append(2*inter/union)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last loss:\t0.2709890902042389\n",
            "Epoch number:\t300\n",
            "Current Learning rate:0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f348dc742aThAxICIEwwx5GUEBBQAVswaqtoK2tYq1trdraVju+2mp/rdWWqhVrcRT3aLWKVhRFZAoSNoQVSIAMssjeN/fz++PexASyDDe5I+/n48GDe8753HPehwNvPvmczxBjDEoppTyfj6sDUEop5Rya0JVSyktoQldKKS+hCV0ppbyEJnSllPISfq66cHR0tBk8eLCrLq+UUh5px44dhcaYmNaOuSyhDx48mNTUVFddXimlPJKInGjrmDa5KKWUl9CErpRSXkITulJKeQlN6Eop5SU0oSullJfQhK6UUl5CE7pSSnmJDhO6iDwvIvkisr+dMrNEZLeIHBCR9c4NsaUjeeX84f00auobuvMySinlcTpTQ18JzGvroIhEAE8BC40xY4BvOie01mUVV/Hspgx2nCjuzssopZTH6TChG2M2AGfaKXID8LYx5qSjfL6TYmvVlKQo/HyEzemF3XkZpZTyOM5oQx8BRIrIZyKyQ0RuaqugiNwmIqkiklpQUNCli4UG+DFxYASbjxV1NV6llPJKzkjofsAFwFXAlcD/iciI1goaY1YYY1KMMSkxMa3OLdMp04ZFsy+rhNKq+i6fQymlvI0zEnoW8JExptIYUwhsACY44bxtmpMci83A+/tyuvMySinlUZyR0N8FZoiIn4gEA1OBg044b5vGJ4QzKq4Pr2w9iS5yrZRSdp3ptvga8DkwUkSyRGSpiNwuIrcDGGMOAh8Ce4EvgGeNMW12cXQGEeHGqYmk5ZYx+6/rWbVHa+pKKdXhfOjGmCWdKPMo8KhTIuqkJVMS8RHhlW0nuPO1XfTvE8iUpL49GYJSSrkVjx0p6usj3DA1kTd/cDEWXx/WHDjt6pCUUsqlPDahNwoJ8OOioVF8eqhbu78rpZTb8/iEDvZeL8cLK7l82XoWPrmJU2eqmo7lllbri1OlVK/gFQl94YR4Fk2MJyk6hL1Zpby7O5vl69LZc6qEaQ9/ynt7c10dolJKdTuXLRLtTJEhFh5fPAmAucvW8/dP06m12liTlocx8Oq2EyycEN/uOYwxiEjTdk5JNX1DLAT6+3Zr7Eop5SxeUUNvbsawaGqtNgD2nCoBYOvxM5woqmzzO3VWG5c+uo7l69IBsNkM8x/fyDMbjnd/wEop5SRel9AvHRENQKC//daGxYYC8FE7vWCO5pdz6kw1j350mPT8cgoraimtrudks7Z4pZRyd16X0GeNiOUfN07mp3Pt08lcProfw2ND2XjUPjtjaVU90x/+lM8Of9krJi2nrOnzG9tPkV1SDUBRZV0PRq6UUufH6xK6j48wf1wcM0fGIAJTk/py6YgYth0/w96sEjYfKyS7pJr39uQy77ENfJyWx4GcMoL8fRkd14eDueWa0JVSHskrXoq2Jrl/H7bcN5u48CAAntuUwcInNxMVYgFg1Z5s6hsMy9elY/HzYVRcGENjQvn0UD7ZxY6EXlHrsviVUuqr8roaenONyXza0Gh+MHMIyf3Dmmrd9Q32vum7T5WQmnmG0fF9GB3fh6LKOvZk2V+mFlVoDV0p5Tm8OqE3svj58Kv5o7h3fjIAKYMim36PDw8kNiyQeWPiGBXXB4BPDtrb16vrG6iqs7LrZDH5ZTWuCV4ppTrJa5tcWjNrRAxP3TiZsfHhzP3beq69IIElUxKbjpdW2xfMqHN0ewTIKanhhme2MX9cf5Z9a2KPx6yUUp3VqxK6iLBgXBwAm+69jOiQgBbHw4P8+eYFCfx7Rxb+vkJ9g+HjtDyq6xvYkl50zuCj1mQWVuLrIwzsG9xt96GUUq3pFU0urYkNC8TH59zk/NDVY7lm0gDudnR7bJxr/XRZDZlFHfdL/8V/9vCrt/c1bb+wJZO/rz3qpKiVUqptvTahtyXQ35dl109smirgYG4ZceGBAHzeiYWpT52p5lTxl4n/tS9O8tbOLKfEtvNkMbes3E59g63jwkqpXkcTehuiQi1Nn5fOSGJwVDB/XXOYg7lfDkL67HB+i0FJDTZDQUUtuaU1GGOwNtg4XlDJ6bIap8z4+PmxIj49lE+hdqdUSrVCE3obgi321wtRIRZunp7E89+7ED9f4a7Xd3GsoIK/rjnM9/61ne+/mEqttQFjDEUVtTTYDHVWGyVV9WQWVVHXYKOm3kZZjfW8YypzvLQtd8K5lFLep1e9FP2qNt83m+hQC74+wpCYUP5w9Ti+/2Iqc/66HoBJiRHsOlnCy1tPsuloAYXN+q3nlta0mBAsr6yG8CD/84qnrKYxodef13mUUt5JE3o7BkQEtdieOyqWH84aigCLL0wkMSqYb/3zc/65/hgFFbU0b1VZdzifjUcLmrbzymoY0S/svOIpq7a2+F0ppZrTJpevQES4d14yv5yXTGKUvVvit1IGkl/eMpkDPPrRYbYeP9O0/ezGDJ7d2P50vJ8dzue+t/bSYGu9vb2xhl6mNXSlVCs6TOgi8ryI5IvI/g7KXSgiVhG5znnhub95Y/sT6O9DYw/I5j0h48IDeeTa8QCsP1LAX9Ycpqa+oc1zPbz6EK9vP8WLn2e2elzb0JVS7elMDX0lMK+9AiLiC/wZWOOEmDxKaIAfDy0ay0NXjwUgOvTLwUovLZ3Kty4c2LRdU28jNbO4zXPZHNX8ZR8fwdpK18TGF6ua0JVSrekwoRtjNgBnOij2E+AtIL+Dcl7pmykDuWFKIlEhFvo7+qwDDI0JOafshmbt6s3VWe1dHBMigyivsXLodPk5ZUqr9aWoUqpt5/1SVEQGAN8ALgMu7KDsbcBtAImJie0V9TgiwrcuHEhogB/3zU8GwznTBMwYFs2Ln2dijOG++aPILq4mq6SKIdGhfHwwD6vNsGRKIo9+dJi1B/Mpra5n+jD7CkzGGG1yUUq1yxm9XB4D7jXG2Dqa58QYswJYAZCSknL+I23czL3zklvd/8Gdl1BZZ6V/n0CWfXyEZzZmkFlURVpOGbml1cSFBzUtqnHZyFhWbsnkb58cAWD/768kNMCP6voGrI6XpVpDV0q1xhkJPQV43ZHMo4EFImI1xrzjhHN7hdHxfZo+/+36iYwdEM6fPjgI2Nvcc0qrm44PjQ0hNMCPgnL7aNCDuWVcOLhvi66KZTVWKmqtrDuUz9fGx3U4YZhSqnc474RujElq/CwiK4H3NZm3b+mMJGaOiKakqp6o0AAyCiuIDQskLbeMAD9f7p2XzGOfHOHQ6XLScsoY2T+sxSLX5TX1PL8pg2UfHyEhMohJiZEtzl9Ra+W5jRncPmsIAX6+PX17SikX6TChi8hrwCwgWkSygAcAfwBjzNPdGp0XGxb75SCjpGj7y9OxA8IBe1fIK8f044I/fMKBnFJ2nSzmnd32WR+DLb6U11j55GAeAGsP5p+T0Ffvy+VvnxxhfEI4lyXH9sTtKKXcQIcJ3RizpLMnM8Z877yiUU1EhNFxfXgzteVMjQMigjhWUNG0hN6T69IJsvjSN8TChYMjeWDVASKC7ROLHTpdrgldqV5Eh/67sXEJ4WxKL2Rg3yBOnbG3sw+IDOJofgUA112QwH92ZPHoR4cBGNEvlCN5FU3fP3y67NyTKqW8liZ0N3bbJUOYNDCCS0fEMPWPaymtrifeMb/M+IRw/nD1WOaOiuXCwX2Z//jGFskcaLUvu1LKe+lcLm4sMsTCFWP6E+jvy6o7pvPzK0Y0zRlz/YUDCfT3Zd7YOKJCA1jsGJE60jEBWEJkY9PMlyNOC8prWfTkJo4XVJxzLaWU59MauocYFBXCHbOHk55fgcVX+OYFA1scv/XSIUSGWLhkeDS/fWc/l4/uz0Pvp3Egp4yJAyMA2JxeyJ6sUtYezOetnVncPD2pxVQFSinPJs5YSacrUlJSTGpqqkuu3RsUVtRy+bL19OsTyC/njeSykbH8/r00Vm7JbGqTv3P2ML6ZMpCEyCDty66UhxCRHcaYlNaOaZOLl4oODWDZ9RPJKKzklpWpvJl6ij1ZJQBNL1j/tTmTSx5Zx1OfHXNlqEopJ9GE7sUuGxnLrvsvZ8LACP6y5gi7Tpa0OF5eax99+tS6dPLLa1wRolLKiTShe7lgix/3XjmyaSqBS4bbJ/v62vg4rhjdjydvmERlXQMvbz3Jtf/YwvbMjibWVEq5K30p2gtMGxbNup/P4kheOX1DLGw8WsjMETF8M8X+YvXxT47yzIbjVNc38N6eHC4c3NfFESulukITei+RFB1CUnQIxhieunEyc0f1azo2fVg0K7dkArS7AIdSyr1pk0svIyIsGBeHxe/LRz/DMee6v69w6HQZ5TX1ZBVXcfmy9azel+uqUJVSX5EmdMW0YVFcMjyau+eOwGbsC1zf9NwXHM2v4NUvTro6PKVUJ2lCVwRb/Hhp6VS+N20wCZFBvPj5Caw2Q3x4IAdyyli+Lp1DOi+MUm5PBxapFowxlFbXEx7kz793ZPHL/+wF7L1jXlo61cXRKaV0YJHqNBEhItiCiHDxkCgALL4+bDxayDu7simtqmf5unR2nyrp4ExKqZ6mNXTVrpe3nmBMfB9ufHYbVXUNBPr7UFNvY0BEEJ/8bCZBFl0RSame1F4NXRO66pSckmoO55Xz2CdHGRoTwts7sxkaE8J980dx+eh+HZ9AKeUU7SV07YeuOiU+Ioj4iCAuG2lfAemipCie2Xicn7y2k7d+OI0x8eEujlAppW3oqku+deFAXv3+RUQEWfjOc1+wN0vb1JVyNU3oqstiwgJ47baLCPL35bp/fM5zmzLIKKyktKre1aEp1St1mNBF5HkRyReR/W0cv1FE9orIPhHZIiITnB+mcldJ0SG895MZXDoimofeT+Oyv3zGRX9ay0ufZ7o6NKV6nc60oa8EngRebON4BjDTGFMsIvOBFYB2WO5F+oZYeOamFN7fm0tZTT0fHcjj/lUHiAkLJLFvMMEWXwZHh7g6TKW8Xqd6uYjIYOB9Y8zYDspFAvuNMQM6Oqf2cvFeNfUNXL9iK/uzSwGIDPbnvZ/MIC48yMWRKeX5enJg0VJgdTuB3CYiqSKSWlBQ4ORLK3cR6O/Ly0unMHdULPPG9Ke6roEfvbKTWmuDq0NTyqs5rYYuIpcBTwEzjDFFHZ1Ta+i9x//25vLjV3cyKq4PN08fzNj4cOoabE2LVyulOq/b+6GLyHjgWWB+Z5K56l2uGh9HYcUYXvw8k1+/vY8giy/GwNp7ZtKvT6Crw1PKa5x3k4uIJAJvA98xxhw5/5CUN/rutMH85/ZphAX60WAz1DXYuHr5Zr7/YiqvbDuhszkq5QQd1tBF5DVgFhAtIlnAA4A/gDHmaeB+IAp4SkQArG39OKB6t8gQCy/fOhVrg+HkmSre2ZXNvqxSPk7LA2DmiBh+dvkIJmhTjFJdonO5KJey2QzZJdWs2pPD85syqKprYNUd01l7KJ+NRwt4eelUHBUFpRQ6OZfyEPllNcx/fCPhwf6cLq2hqq6BD+68hNHxfVwdmlJuQ+dDVx4htk8gT904maziaqrqGvAReGFLJscKKprKrDuUzw9eSsVmc01FRCl3pglduZWpQ6J46ZYpPHrdeKYmRfFG6imuemIj2SXV5JXV8NoXJ/noQB6HTpe7OlSl3I5On6vcztQhUUwdEsXwfmGs3pfLMxuPM/ev6/ER8HG0p285VqhNMUqdRWvoym1NHBjBrxaM4prJCVhtNirrGiivtQKwOb3QxdEp5X40oSu398dvjGP9Ly7jkuHRAMwb058tx4p4blMG9Q02F0enlPvQJhfl9ix+PsRHBPHA18eQmnmGS0fEUF5bz0Pvp7Fqdzavfv8iQgL0r7JSWkNXHmNYbCiLpyQSHxHEK7dexBNLJrEvu5T73z3g6tCUcgtarVEea+GEeNLzynni03Qsfj70DfFn1shYlq05wnenDaasup7rLkjAx0cHJqneQRO68mh3zx3BsYJKXvviJAAvbjlBea2Vz4/b54gLD/YnLNCPCwf3xd9XfyBV3k1HiiqPZ22wcbywkt/8dx/bM4u5c85w4sID+euaI1TU1lNTbyMpOoR/334x0aEBrg5XqfOiI0WVV/Pz9WFEvzAeunos16cM5EezhrJkSiLXXjCAmnobs5NjySis5NmNGSxfl87vVh2grObLhaxPnania3/fSHp+RTtXUcr9aZOL8hrJ/fvw5+vGN23ffulQokIs3HTxYG59IZWn1x9rOhYe5M9PLx8BwN8/Pcr+7DK2Hi9iWGxoj8etlLNoDV15rcgQC7ddOpRAf19umTEYXx/hkWvHc8XofvxrcwblNfWcLKrirZ3ZAJwoqnRxxEqdH62hq15hdnI/dt9/OWGB/iTHhbEmLY+Xt54ks7ASXx8hKsTCiaIqV4ep1HnRhK56jbBAfwDGJ0RwyfBonl5/jMpaK9++aBBZxVWa0JXH0yYX1SvdPXcEVXVWLh4axU9mD2NQVAgnzlTiql5fSjmD1tBVr3TBoEgOPjgPP0ff9EFRwdTU28h1LKxhtdn4v3f289urRuuSeMpjaEJXvZZfs4FGg6JCAJi7bD1VdQ1N+1/Yksmy6yf2eGxKdYUmdKWACQnhTBgYwZDoECYPimR/Vim7ThWz4WghNpthW8YZJiVGEOjv6+pQlWpThwldRJ4HvgbkG2PGtnJcgMeBBUAV8D1jzE5nB6pUd4oItvDuj6e32Pfu7mzuen03d72xm/f25HDrjCR++7XRLopQqY515qXoSmBeO8fnA8Mdv24D/nH+YSnlerNGxpLYN5j39uQQ5O/LG9tPUeFYYEMpd9RhQjfGbADOtFNkEfCisdsKRIhInLMCVMpVwoP8+fSembx3xwxeWjqF8lor/9qU4eqwlGqTM7otDgBONdvOcuw7h4jcJiKpIpJaUFDghEsr1b38fH0YlxBOyuC+XDUujic+PcrKzRlUN3tx2mjLsUJOl9a4IEql7Hq0H7oxZoUxJsUYkxITE9OTl1bqvD109ViGxoTyu/fS+OVbe1scK62q56bnvuCxT464KDqlnJPQs4GBzbYTHPuU8ip9QyysvusS7pwznPf25PDpobymY58dycdqM+w6WeLCCFVv54xui6uAO0TkdWAqUGqMyXXCeZVyOyLCjy8bypoDp/npG3uICw8kPiKI4qo6AI7kl1NRayVU1zhVLtBhDV1EXgM+B0aKSJaILBWR20XkdkeRD4DjQDrwDPCjbotWKTcQ4OfLP79zAf6+Plj8fDiQU8qukyUMjgrGGNibpbV05Rq6YpFSXWSzGXx8BGuDjR0niukfHsjMRz8D0D7rqtvoikVKdYPGxaf9fH2YOiSKQVEhfPfiQUxKjODZTRm8vTPLxRGq3kYb+pRyot8vGou1wca3n9vGr97ex7DYUMYn6OReqmdoDV0pJ/Pz9eHJGybTN8TCdU9/zlOfpWNtsLk6LNULaEJXqhtEhwaw6o4ZzEmO5ZEPD3PvW/tcHZLqBbTJRaluEhMWwD++fQF/+uAg/9xwnMhgf6w2w4JxcaQMiqSuwUaAnw/2+e2UOn+a0JXqZj+ZM5z/7srmuc0Z+Pv4sD3zDDFhAXx2uIAlUxL50zXjXB2i8hKa0JXqZqEBfrx/5wwA3t6ZzcOrDwHgI/DJwTz+aMZqLV05hbahK9UDYsMCiQ0LZE5ybNO+W6YnUVBey+kyndBLOYcmdKV60LDYUJKiQ0gZFMmC8fZZptcdKqCwotbFkSlvoE0uSvUgEeHFW6Zg8fMhPMgfgF//dx9Prz/Gf380DV8fISLY4uIolafSGrpSPWxg32D69Qkk0N+X2LAAAE6eqeKiP61l0fLN1NSfO9e6Up2hCV0pF3rjBxez9p6ZXDUujsS+wZwoquKRDw9TZ7Vx6kwVmYWVrg5ReRCdnEspN2CMQUS45809vLUziyB/X2qtDUQGW9h832wC/X1dHaJyEzo5l1JurrHb4l++OZ4Xb5nC4ikD+cakBIoq63h/by5VdVbytDeM6oDW0JVyU8YYLv/bBuodI0qLq+rZct9s/H21HtabaQ1dKQ8kIvzh6rEUV9ZxJK+CgvJaNh7VxdVV2zShK+XGLhoSxYd3X8qqO6YTGezPO7tyXB0SAOsO5VNVZ3V1GOosmtCVcnPxEUGMT4hg0cQBvL83h9X7XLtkb35ZDTev3M77e3TpYHejCV0pD3HvvGQmDozgR6/u5IF391NT30BpVX2Px1Fabb9mWU3PX1u1T0eKKuUhgiy+vLR0Ko9+dJiVWzJ5MzULPx/hnTumMzQmtMfiqKi1N7XoACj306kauojME5HDIpIuIve1cjxRRNaJyC4R2SsiC5wfqlIqJMCP3y0cw4OLxnDRkL74+/lw+0s7qKztufbsylp7Iq+p11WY3E2HCV1EfIHlwHxgNLBERM5ezvy3wJvGmEnAYuApZweqlPrSTRcP5l83T+HvSyZxrKCCe9/aS091QW6soVdrDd3tdKbJZQqQbow5DiAirwOLgLRmZQzQx/E5HHCPV/FKebnpw6L5+ZUjeeTDw0SFWBg7IJzrLkjo1vnVG3u3aEJ3P51J6AOAU822s4CpZ5X5HbBGRH4ChABznRKdUqpDP5w5lN0nS3jh8xMABFv8uGp8HDX1Dd0yZUCltqG7LWf1clkCrDTGJAALgJdE5Jxzi8htIpIqIqkFBTpAQilnEBH+fsMkVt91CeMGhHP/u/t5ePUhJj/0MTtOFDv9ehVNbeia0N1NZxJ6NjCw2XaCY19zS4E3AYwxnwOBQPTZJzLGrDDGpBhjUmJiYroWsVLqHAF+voyK68Mj142ntLqep9cfo6qugR+8lNrUzdBZvqyh60tRd9OZhL4dGC4iSSJiwf7Sc9VZZU4CcwBEZBT2hK5VcKV62Ki4PvzsihH0DbHw9LcvoLCijhe3ZDr1GpWNbeh1WkN3Nx0mdGOMFbgD+Ag4iL03ywEReVBEFjqK3QN8X0T2AK8B3zOumvVLqV7uR7OGse3Xc5g3tj9zkmN5bnMGmYWVGGOaeqi05kRRJdMf/pQTRe3Pwd5UQ7dqQnc3nRpYZIz5APjgrH33N/ucBkx3bmhKqa5qnJHx3vnJLF6xlUXLN5PcP4xdp0r48K5LGNLKQKSdJ4vJLqkmNbOYQVEhbZ67sR+61tDdjw79V8qLjegXxls/nMb4hHDScsqw2QyvfXGSw6fLWbR8M//b++V8LCeLqgHI7KCG3ljLr7VqG7q70aH/Snm5pOgQXlpq72n8w5d38NbObCpqG9hzqoQfv7qTBjOJhRPiOXHGnsiPd7DsXZW2obstraEr1Yt85+JBnKms47UvTjInOZbJiRH85r/7yCqu4tSZKgAyCjqqoTuaXLTbotvRhK5ULzJtaDSzRtq7DH99QjyPL56EMfDTN3aTUWhP6JlFle1OI6ADi9yXJnSlepnfLxzD9SkDuWJMPwb2DebBRWPYnllMYUUtMWEBVNU1kF9e2+b3K5u1odtsnevMVlZTT522uXc7TehK9TKDokL483XjCbbYX6F9Y9IAQiz2KQKmD40CYOeJYspr6lutqVfWWWmcKqazL0YX/n0TT32W7oToVXs0oSvVyzVOHQDww1nDSIoO4d639jLud2uYs2w9z2w43tS8Ym2wUVNvIzLYAnSuHd1mM5w8U8WJoqruuwkFaEJXSgGzk/tx/I8LGNk/jPu/NpryWitXjY8jMtjC//vgILes3E5VnZVKR8+W6FB7Qu9MO3pFnRWbgZKqum69B6XdFpVSDj4+9naUy5Jj2fnby4kI9kdEeHtnFvf8ew8PvpfGD2YOBSA6NIAjeRWdqqE3LpPn7Dll1Lk0oSulzhEZYmn6fM3kBI7mV/CPz46RU1oDwGUjY9lyrKhTNfTGtUc1oXc/bXJRSnXop3NHMDQmhA1HCpg4MIIR/cOAzjW5NCZyTejdTxO6UqpDFj8f7v/6GACumTyAIMfCGZ2ZQresWULXOfu6lyZ0pVSnzBwRw+q7LuHGqYOaEnrj8P+jeeUseHwjH+7PPed7ZdX2fuv1DYYqnS6gW2lCV0p12qi4Pvj6CIH+9tRRXd9AfnkNi1dsJS23jMfXpp9TC2/e1NJas8uqPTlsOVbYvYH3EprQlVJfWeNapdX1Dfzmv/spr7Vy8/TBHMwtY/epkhZlmyfxkqpzE/r/+18az2w43r0B9xKa0JVSX1lEsD8WXx8e+fAwH6fl8YsrRnLPFSOx+Pqwev/pFmUbe7nAuTX08pp68spqKW4l0auvThO6UuorCwv054klkyivqee7Fw/i1kuSCA3wY+yAPuw8a2Hq9ppcMhxT9RbroCOn0H7oSqkumTe2P7vvv4IgxzwwAJMSI3lp6wnqrDYsfvb6Yml1PVEhFooq6yitbpm4jxVUAHCmUhO6M2gNXSnVZc2TOcDkxEjqrDYO5pY17SurricxKhg4t4Z+3DH3enmNlfoGnY3xfGlCV0o5zeRBEQA8sfYopx2jSkur64kLD8TPR855KXq82WIa2uxy/jShK6WcJi48iDsuG8am9EJuen4bFbVWSqvrCQ/yZ0BkEG/tzCItx157f2P7SdYfKcDPMYdMcaW+GD1fnUroIjJPRA6LSLqI3NdGmW+JSJqIHBCRV50bplLKU/z8ypE8/70LOVZQyZV/20BhRR1j4sN56sbJ1DcYln18hMpaK//37gGGxoTwwNdHA9qO7gwdJnQR8QWWA/OB0cASERl9VpnhwK+A6caYMcDd3RCrUspDTB8WzZNLJlFYUcvcUf24YUoiY+LDuWJ0P7ZlFPHJwTzqrDZ+vWAUFyb1BbTJxRk608tlCpBujDkOICKvA4uAtGZlvg8sN8YUAxhj8p0dqFLKs8wfF8fUIVGEB/k3Tc07bVg0r28/xV/WHCY61ELK4L4UVdiXu9Ma+vnrTJPLAOBUs+0sx77mRgAjRGSziGwVkXmtnUhEbhORVBFJLSgo6FrESimP0TfEgq8jmQNcPMS+xN2pM9UsmjgAXx8hwrH6UQmenSwAAA5ZSURBVLEm9PPmrH7ofsBwYBaQAGwQkXHGmBZjgI0xK4AVACkpKTrtmlK9TExYANdMGkCfIH/um58M2GdyDAvw44w2uZy3ziT0bGBgs+0Ex77msoBtxph6IENEjmBP8NudEqVSymssu37iOfsiQywUVmhCP1+daXLZDgwXkSQRsQCLgVVnlXkHe+0cEYnG3gSjs+0opTplUmIEH+7PZcWGYxw6XdbxF1SrOkzoxhgrcAfwEXAQeNMYc0BEHhSRhY5iHwFFIpIGrAN+YYwp6q6glVLe5cGFYxkUFcIfPzjEzf+yL0itvjpx1QoiKSkpJjU11SXXVkq5nzqrjU3pBdyyMpXRcX2YPiyKO+cMJyzQv6nM6n255JbWcMuMJBdG6loissMYk9LaMR0pqpRyCxY/H2Yn9+PWGUnYjOHZTRnc/fruFmVe/eIkK3Tu9DbpbItKKbfy26/Zxy0++F4ar2w7Qa21gQA/+yRgBeW15JfXYG2w4eer9dGz6Z+IUsotXTSkL7VWG3tOlTbtyy+vxWYgr7zWhZG5L03oSim3NMUxJcAXGfb+FXVWW9No0tySapfF5c60yUUp5ZYigi0k9w/jibXpZJdU85PZw5uO5Tqm5lUtaQ1dKeW2Hvj6GKYk9eX17afY02zx6dzSaqwNNmrqG1wYnfvRhK6UclsXD43i4WvHAfDkuvSm/TklNSxesZV5j21wVWhuSZtclFJuLSEymEuGx7DhiH1Cv7BAP1ZuyWw6fqayjr4hFhdF5160hq6UcnuLJsQ3fY4LD2xxbG9WydnFey1N6Eoptzd3dL+mzz+aNYwlUway5b7ZAOzLKm3ra72ONrkopdxeeJA/g6OCKa+xcvWkAVw9yb4kw5CYEPZoQm+iNXSllEf46KeXstlRK280OTGSjUcL+O+urBb7/7c3l6uXbyaruKonQ3Q5TehKKY8Q4OdLoL9vi333zktmUmIEP3tzD2sP5jXtf3nrCXafKuGm577AZus9a+loQldKeayYsAD+9b0pjI0P52dv7qG0uh5rg40TRZUAHC+s5NDp8hbfabAZ8sq8c2CSJnSllEcLsvjy52vHU1pdz+XL1jPud2vIKa3h5umDAdiW0XJphrd2ZHHJI+u8clFqTehKKY83Or4PiybGc6ayjmrH6NF5Y/qTEBnEtuNnWpTdcaKYOquNtBzvWxlJE7pSyis8ct14Nt375UvTMQPCmZoUxbaMIqwNtqb9Bx1L3HnjUnea0JVSXiHAz5f+4YGsvWcmjy+eSGiAH/PH9qe4qp53d+cAYG2wcdjRpn4wt7zV81gbbKw9mIerVnM7H5rQlVJeZWhMKIsm2vupzxkVS3L/MJavS6fBZsgsqqLWakMEDue1XkNfk5bH0hdS2euB/ds1oSulvJaIcOec4RwvrOR/+3I5kGNP0tOGRnEkr6JFU0yjxhr8iTOe14e9UwldROaJyGERSReR+9opd62IGBFpdQFTpZTqafPG9Gd4bCh/+/gIj31ylLjwQK6ZlECd1ca+7HNr4ccKKgA8clBShwldRHyB5cB8YDSwRERGt1IuDLgL2ObsIJVSqqt8fITffm00BeW1ZBZV8rfrJzI7ORYfgXWH8skvq+FPqw+y40QxAOn59oSeXex5qyJ1Zi6XKUC6MeY4gIi8DiwC0s4q9xDwZ+AXTo1QKaXO08wRMWz79RxOl9UwNCYUgAsGRbL2UD7V9Q08szGDf64/zn3zk8kotA9KyvLAhN6ZJpcBwKlm21mOfU1EZDIw0Bjzv/ZOJCK3iUiqiKQWFBR85WCVUqqrQgL8mpI5wOzkfhzIKeP17ae4bGQMV42P4+HVh5pemmZ74Lql5/1SVER8gGXAPR2VNcasMMakGGNSYmJizvfSSinVZTdMTWRIdAjlNVYWT0nk8esnEu+Ya31CQgRZxVUe13WxM00u2cDAZtsJjn2NwoCxwGciAtAfWCUiC40xqc4KVCmlnCk8yJ8XbpnC//blMic5Fj9fH1bffSn/25tLdX0Du0+VUFRZR25JDWMH9MGR39xaZ2ro24HhIpIkIhZgMbCq8aAxptQYE22MGWyMGQxsBTSZK6Xc3sC+wdw+cyh+vvZUGB7kzw1TExkcFQzAPW/u4etPbmLj0cJzvnv4dLnb1eA7TOjGGCtwB/ARcBB40xhzQEQeFJGF3R2gUkr1tOnDounXJ4D1jnVM16SdZt5jG0jPr+BATikHckq58rENvLc318WRtiSu+h8mJSXFpKZqJV4p5Z5e2JLJA6sOAODnI1hthnEDwtmXXcoFgyLZcaKYayYNYNn1E3s0LhHZYYxpdayPjhRVSqlWfPuiQbxy61SuHNMPq2ORjMaBSI191jccLXSrZhdN6Eop1QpfH2H6sGjGDQgHoH8few+YsAB7X5KwQD8KK2rPWUDDlTShK6VUOyYMjADgga+P5qFFY3j42vEA3DxtMACpmWfa+mqP60y3RaWU6rVmDIvmlVunMm1oFCKCzWZY9q0JLBgXxwufnyAt99xZG3NKqokNC2jqPdNTtIaulFLtELE3vTT2Q/fxEa6ZnECgvy9j4vucs/JRfnkNs/7yGW+knmrtdN1KE7pSSnXR6Lg+HDpd3mIa3s3phdRZbezILO7xeLTJRSmlumh0fB9qrTY+PHCa4bFh3PX6Luodyb21qXm7myZ0pZTqovEJ9hemd7y6CxFo3oPxWEEFVXVWgi09l2a1yUUppbpoWGwob/7gYp5YMok5yf145NrxhAb4sXBCPDbz5bqlNlvP9FXXGrpSSp2HKUl9AVg4IR6Ab0weQGFFLav25PDOrmwGRQUz//GN3HHZML7r6OrYXbSGrpRSTuTv60NceBDfvXgQL209wbX/2EJBeS3Pb87o9pq6JnSllOoGD3x9DLfPHEpWcTWj4vpwoqiKrceLuvWaOjmXUkp1o6KKWoItfsz486cMigrmoiFRzBnVjwsGRXbpfDo5l1JKuUhUaABBFl9+tWAUO0+W8NRnx5qm5XU2fSmqlFI94NrJA8gqrmJMfDiXj+7XLdfQhK6UUj1ARLh77ohuvYY2uSillJfQhK6UUl5CE7pSSnkJTehKKeUlOpXQRWSeiBwWkXQRua+V4z8TkTQR2Ssia0VkkPNDVUop1Z4OE7qI+ALLgfnAaGCJiIw+q9guIMUYMx74D/CIswNVSinVvs7U0KcA6caY48aYOuB1YFHzAsaYdcaYKsfmViDBuWEqpZTqSGcS+gCg+VpKWY59bVkKrD6foJRSSn11Th1YJCLfBlKAmW0cvw24zbFZISKHu3ipaKCwi991N3ov7slb7sVb7gP0Xhq1+Y6yMwk9GxjYbDvBsa8FEZkL/AaYaYypbe1ExpgVwIpOXLNdIpLa1uQ0nkbvxT15y714y32A3ktndKbJZTswXESSRMQCLAZWnRXcJOCfwEJjTL6zg1RKKdWxDhO6McYK3AF8BBwE3jTGHBCRB0VkoaPYo0Ao8G8R2S0iq9o4nVJKqW7SqTZ0Y8wHwAdn7bu/2ee5To6rI+fdbONG9F7ck7fci7fcB+i9dMhlC1wopZRyLh36r5RSXkITulJKeQmPS+gdzSvj7kQkU0T2OV4epzr29RWRj0XkqOP3ri022M1E5HkRyReR/c32tRq72D3heE57RWSy6yJvqY37+J2IZDuey24RWdDs2K8c93FYRK50TdStE5GBIrLOMZfSARG5y7Hfo55LO/fhcc9FRAJF5AsR2eO4l9879ieJyDZHzG84eg0iIgGO7XTH8cFdvrgxxmN+Ab7AMWAIYAH2AKNdHddXvIdMIPqsfY8A9zk+3wf82dVxthH7pcBkYH9HsQMLsI8YFuAiYJur4+/gPn4H/LyVsqMdf88CgCTH3z9fV99Ds/jigMmOz2HAEUfMHvVc2rkPj3sujj/bUMdnf2Cb48/6TWCxY//TwA8dn38EPO34vBh4o6vX9rQaeofzynioRcALjs8vAFe7MJY2GWM2AGfO2t1W7IuAF43dViBCROJ6JtL2tXEfbVkEvG6MqTXGZADp2P8eugVjTK4xZqfjczn2rsUD8LDn0s59tMVtn4vjz7bCsenv+GWA2dgnL4Rzn0njs/oPMEdEpCvX9rSE/lXnlXFHBlgjIjscUyEA9DPG5Do+nwa6ZwXZ7tFW7J74rO5wNEM836zZy2Puw/Gj+iTsNUKPfS5n3Qd44HMREV8R2Q3kAx9j/wmixNjH9UDLeJvuxXG8FIjqynU9LaF7gxnGmMnYpyP+sYhc2vygsf/c5ZF9ST05duAfwFBgIpAL/NW14Xw1IhIKvAXcbYwpa37Mk55LK/fhkc/FGNNgjJmIfaqUKUByT1zX0xJ6p+aVcWfGmGzH7/nAf7E/7LzGH3sdv3vS9Altxe5Rz8oYk+f4R2gDnuHLH9/d/j5ExB97EnzFGPO2Y7fHPZfW7sOTnwuAMaYEWAdcjL15q3EwZ/N4m+7FcTwcKOrK9TwtoXc4r4w7E5EQEQlr/AxcAezHfg/fdRT7LvCuayLskrZiXwXc5OhVcRFQ2qwJwO2c1Y78DezPBez3sdjREyEJGA580dPxtcXR1voccNAYs6zZIY96Lm3dhyc+FxGJEZEIx+cg4HLs7wTWAdc5ip39TBqf1XXAp46fqr46V78R7sIb5AXY34AfA37j6ni+YuxDsL+Z3wMcaIwfe3vZWuAo8AnQ19WxthH/a9h/7K3H3ga4tK3Ysb/pX+54Tvuwr2jl8nto5z5ecsS51/EPLK5Z+d847uMwMN/V8Z91LzOwN6fsBXY7fi3wtOfSzn143HMBxmNfxW0v9v+A7nfsH4L9P5104N9AgGN/oGM73XF8SFevrUP/lVLKS3hak4tSSqk2aEJXSikvoQldKaW8hCZ0pZTyEprQlVLKS2hCV0opL6EJXSmlvMT/B3pY27cyZRYaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VY9Qzq5_tqy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}